<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/EeaWOh7zx5m3yWhaebbP3MKC9+8</id>
  <title>arXiv Query: search_query=au:"Judea Pearl"&amp;id_list=&amp;start=0&amp;max_results=50</title>
  <updated>2026-02-07T20:04:20Z</updated>
  <link href="https://arxiv.org/api/query?search_query=au:%22Judea+Pearl%22&amp;start=0&amp;max_results=50&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>50</opensearch:itemsPerPage>
  <opensearch:totalResults>62</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2505.17133v1</id>
    <title>Learning Probabilities of Causation from Finite Population Data</title>
    <updated>2025-05-22T03:31:44Z</updated>
    <link href="https://arxiv.org/abs/2505.17133v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2505.17133v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Probabilities of causation play a crucial role in modern decision-making. This paper addresses the challenge of predicting probabilities of causation for subpopulations with \textbf{insufficient} data using machine learning models. Tian and Pearl first defined and derived tight bounds for three fundamental probabilities of causation: the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). However, estimating these probabilities requires both experimental and observational distributions specific to each subpopulation, which are often unavailable or impractical to obtain with limited population-level data. Therefore, for most subgroups, the amount of data they have is not enough to guarantee the accuracy of their probabilities. Hence, to estimate these probabilities for subpopulations with \textbf{insufficient} data, we propose using machine learning models that draw insights from subpopulations with sufficient data. Our evaluation of multiple machine learning models indicates that, given the population-level data and an appropriate choice of machine learning model and activation function, PNS can be effectively predicted. Through simulation studies on multiple Structured Causal Models (SCMs), we show that our multilayer perceptron (MLP) model with the Mish activation function achieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS for $32,768$ subpopulations across most SCMs using data from only $2,000$ subpopulations with known PNS values.</summary>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-05-22T03:31:44Z</published>
    <arxiv:comment>arXiv admin note: text overlap with arXiv:2502.08858</arxiv:comment>
    <arxiv:primary_category term="stat.ML"/>
    <author>
      <name>Shuai Wang</name>
    </author>
    <author>
      <name>Song Jiang</name>
    </author>
    <author>
      <name>Yizhou Sun</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
    <author>
      <name>Ang Li</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2301.12022v1</id>
    <title>Epsilon-Identifiability of Causal Quantities</title>
    <updated>2023-01-27T23:16:57Z</updated>
    <link href="https://arxiv.org/abs/2301.12022v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2301.12022v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Identifying the effects of causes and causes of effects is vital in virtually every scientific field. Often, however, the needed probabilities may not be fully identifiable from the data sources available. This paper shows how partial identifiability is still possible for several probabilities of causation. We term this epsilon-identifiability and demonstrate its usefulness in cases where the behavior of certain subpopulations can be restricted to within some narrow bounds. In particular, we show how unidentifiable causal effects and counterfactual probabilities can be narrowly bounded when such allowances are made. Often those allowances are easily measured and reasonably assumed. Finally, epsilon-identifiability is applied to the unit selection problem.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <published>2023-01-27T23:16:57Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Scott Mueller</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.08874v1</id>
    <title>Probabilities of Causation: Role of Observational Data</title>
    <updated>2022-10-17T09:10:11Z</updated>
    <link href="https://arxiv.org/abs/2210.08874v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2210.08874v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Probabilities of causation play a crucial role in modern decision-making. Pearl defined three binary probabilities of causation, the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). These probabilities were then bounded by Tian and Pearl using a combination of experimental and observational data. However, observational data are not always available in practice; in such a case, Tian and Pearl's Theorem provided valid but less effective bounds using pure experimental data. In this paper, we discuss the conditions that observational data are worth considering to improve the quality of the bounds. More specifically, we defined the expected improvement of the bounds by assuming the observational distributions are uniformly distributed on their feasible interval. We further applied the proposed theorems to the unit selection problem defined by Li and Pearl.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-10-17T09:10:11Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.08453v1</id>
    <title>Learning Probabilities of Causation from Finite Population Data</title>
    <updated>2022-10-16T05:46:25Z</updated>
    <link href="https://arxiv.org/abs/2210.08453v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2210.08453v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper deals with the problem of learning the probabilities of causation of subpopulations given finite population data. The tight bounds of three basic probabilities of causation, the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN), were derived by Tian and Pearl. However, obtaining the bounds for each subpopulation requires experimental and observational distributions of each subpopulation, which is usually impractical to estimate given finite population data. We propose a machine learning model that helps to learn the bounds of the probabilities of causation for subpopulations given finite population data. We further show by a simulated study that the machine learning model is able to learn the bounds of PNS for 32768 subpopulations with only knowing roughly 500 of them from the finite population data.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-10-16T05:46:25Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Song Jiang</name>
    </author>
    <author>
      <name>Yizhou Sun</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.08203v1</id>
    <title>Unit Selection: Learning Benefit Function from Finite Population Data</title>
    <updated>2022-10-15T05:48:01Z</updated>
    <link href="https://arxiv.org/abs/2210.08203v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2210.08203v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The unit selection problem is to identify a group of individuals who are most likely to exhibit a desired mode of behavior, for example, selecting individuals who would respond one way if incentivized and a different way if not. The unit selection problem consists of evaluation and search subproblems. Li and Pearl defined the "benefit function" to evaluate the average payoff of selecting a certain individual with given characteristics. The search subproblem is then to design an algorithm to identify the characteristics that maximize the above benefit function. The hardness of the search subproblem arises due to the large number of characteristics available for each individual and the sparsity of the data available in each cell of characteristics. In this paper, we present a machine learning framework that uses the bounds of the benefit function that are estimable from the finite population data to learn the bounds of the benefit function for each cell of characteristics. Therefore, we could easily obtain the characteristics that maximize the benefit function.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-10-15T05:48:01Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Song Jiang</name>
    </author>
    <author>
      <name>Yizhou Sun</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.05030v1</id>
    <title>Unit Selection: Case Study and Comparison with A/B Test Heuristic</title>
    <updated>2022-10-10T22:09:35Z</updated>
    <link href="https://arxiv.org/abs/2210.05030v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2210.05030v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The unit selection problem defined by Li and Pearl identifies individuals who have desired counterfactual behavior patterns, for example, individuals who would respond positively if encouraged and would not otherwise. Li and Pearl showed by example that their unit selection model is beyond the A/B test heuristics. In this paper, we reveal the essence of the A/B test heuristics, which are exceptional cases of the benefit function defined by Li and Pearl. Furthermore, We provided more simulated use cases of Li-Pearl's unit selection model to help decision-makers apply their model correctly, explaining that A/B test heuristics are generally problematic.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-10-10T22:09:35Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2210.05027v1</id>
    <title>Probabilities of Causation: Adequate Size of Experimental and Observational Samples</title>
    <updated>2022-10-10T21:59:49Z</updated>
    <link href="https://arxiv.org/abs/2210.05027v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2210.05027v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The probabilities of causation are commonly used to solve decision-making problems. Tian and Pearl derived sharp bounds for the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN) using experimental and observational data. The assumption is that one is in possession of a large enough sample to permit an accurate estimation of the experimental and observational distributions. In this study, we present a method for determining the sample size needed for such estimation, when a given confidence interval (CI) is specified. We further show by simulation that the proposed sample size delivered stable estimations of the bounds of PNS.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-10-10T21:59:49Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Ruirui Mao</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.09569v1</id>
    <title>Unit Selection with Nonbinary Treatment and Effect</title>
    <updated>2022-08-20T00:01:46Z</updated>
    <link href="https://arxiv.org/abs/2208.09569v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2208.09569v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The unit selection problem aims to identify a set of individuals who are most likely to exhibit a desired mode of behavior, for example, selecting individuals who would respond one way if encouraged and a different way if not encouraged. Using a combination of experimental and observational data, Li and Pearl derived tight bounds on the "benefit function", which is the payoff/cost associated with selecting an individual with given characteristics. This paper extends the benefit function to the general form such that the treatment and effect are not restricted to binary. We propose an algorithm to test the identifiability of the nonbinary benefit function and an algorithm to compute the bounds of the nonbinary benefit function using experimental and observational data.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-08-20T00:01:46Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.09568v1</id>
    <title>Probabilities of Causation with Nonbinary Treatment and Effect</title>
    <updated>2022-08-19T23:54:47Z</updated>
    <link href="https://arxiv.org/abs/2208.09568v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2208.09568v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper deals with the problem of estimating the probabilities of causation when treatment and effect are not binary. Tian and Pearl derived sharp bounds for the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN) using experimental and observational data. In this paper, we provide theoretical bounds for all types of probabilities of causation to multivalued treatments and effects. We further discuss examples where our bounds guide practical decisions and use simulation studies to evaluate how informative the bounds are for various combinations of data.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-08-19T23:54:47Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2208.09558v1</id>
    <title>Personalized Decision Making -- A Conceptual Introduction</title>
    <updated>2022-08-19T22:21:29Z</updated>
    <link href="https://arxiv.org/abs/2208.09558v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2208.09558v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Personalized decision making targets the behavior of a specific individual, while population-based decision making concerns a sub-population resembling that individual. This paper clarifies the distinction between the two and explains why the former leads to more informed decisions. We further show that by combining experimental and observational studies we can obtain valuable information about individual behavior and, consequently, improve decisions over those obtained from experimental studies alone.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-08-19T22:21:29Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Scott Mueller</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2109.07556v1</id>
    <title>Unit Selection with Causal Diagram</title>
    <updated>2021-09-15T20:06:25Z</updated>
    <link href="https://arxiv.org/abs/2109.07556v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2109.07556v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The unit selection problem aims to identify a set of individuals who are most likely to exhibit a desired mode of behavior, for example, selecting individuals who would respond one way if encouraged and a different way if not encouraged. Using a combination of experimental and observational data, Li and Pearl derived tight bounds on the "benefit function" - the payoff/cost associated with selecting an individual with given characteristics. This paper shows that these bounds can be narrowed significantly (enough to change decisions) when structural information is available in the form of a causal model. We address the problem of estimating the benefit function using observational and experimental data when specific graphical criteria are assumed to hold.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2021-09-15T20:06:25Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2106.12121v1</id>
    <title>Bounds on Causal Effects and Application to High Dimensional Data</title>
    <updated>2021-06-23T01:47:38Z</updated>
    <link href="https://arxiv.org/abs/2106.12121v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2106.12121v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper addresses the problem of estimating causal effects when adjustment variables in the back-door or front-door criterion are partially observed. For such scenarios, we derive bounds on the causal effects by solving two non-linear optimization problems, and demonstrate that the bounds are sufficient. Using this optimization method, we propose a framework for dimensionality reduction that allows one to trade bias for estimation power, and demonstrate its performance using simulation studies.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2021-06-23T01:47:38Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2104.13730v2</id>
    <title>Causes of Effects: Learning individual responses from population data</title>
    <updated>2021-05-02T06:48:55Z</updated>
    <link href="https://arxiv.org/abs/2104.13730v2" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2104.13730v2" rel="related" type="application/pdf" title="pdf"/>
    <summary>The problem of individualization is recognized as crucial in almost every field. Identifying causes of effects in specific events is likewise essential for accurate decision making. However, such estimates invoke counterfactual relationships, and are therefore indeterminable from population data. For example, the probability of benefiting from a treatment concerns an individual having a favorable outcome if treated and an unfavorable outcome if untreated. Experiments conditioning on fine-grained features are fundamentally inadequate because we can't test both possibilities for an individual. Tian and Pearl provided bounds on this and other probabilities of causation using a combination of experimental and observational data. Even though those bounds were proven tight, narrower bounds, sometimes significantly so, can be achieved when structural information is available in the form of a causal model. This has the power to solve central problems, such as explainable AI, legal responsibility, and personalized medicine, all of which demand counterfactual logic. We analyze and expand on existing research by applying bounds to the probability of necessity and sufficiency (PNS) along with graphical criteria and practical applications.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2021-04-28T12:38:11Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Scott Mueller</name>
    </author>
    <author>
      <name>Ang Li</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.04016v1</id>
    <title>Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution</title>
    <updated>2018-01-11T23:37:48Z</updated>
    <link href="https://arxiv.org/abs/1801.04016v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1801.04016v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2018-01-11T23:37:48Z</published>
    <arxiv:comment>8 pages, 3 figures</arxiv:comment>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1801.03583v2</id>
    <title>Graphical Models for Processing Missing Data</title>
    <updated>2019-11-13T20:50:41Z</updated>
    <link href="https://arxiv.org/abs/1801.03583v2" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1801.03583v2" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: \textit{transparency, estimability and testability}. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are Missing Not At Random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally we derive testable implications for missing data models in both MAR (Missing At Random) and MNAR categories.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2018-01-10T23:26:02Z</published>
    <arxiv:comment>34 pages, 5 figures</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Karthika Mohan</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1511.02995v3</id>
    <title>Incorporating Knowledge into Structural Equation Models using Auxiliary Variables</title>
    <updated>2016-05-03T01:19:50Z</updated>
    <link href="https://arxiv.org/abs/1511.02995v3" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1511.02995v3" rel="related" type="application/pdf" title="pdf"/>
    <summary>In this paper, we extend graph-based identification methods by allowing background knowledge in the form of non-zero parameter values. Such information could be obtained, for example, from a previously conducted randomized experiment, from substantive understanding of the domain, or even an identification technique. To incorporate such information systematically, we propose the addition of auxiliary variables to the model, which are constructed so that certain paths will be conveniently cancelled. This cancellation allows the auxiliary variables to help conventional methods of identification (e.g., single-door criterion, instrumental variables, half-trek criterion), as well as model testing (e.g., d-separation, over-identification). Moreover, by iteratively alternating steps of identification and adding auxiliary variables, we can improve the power of existing identification methods via a bootstrapping approach that does not require external knowledge. We operationalize this method for simple instrumental sets (a generalization of instrumental variables) and show that the resulting method is able to identify at least as many models as the most general identification method for linear systems known to date. We further discuss the application of auxiliary variables to the tasks of model testing and z-identification.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2015-11-10T05:19:00Z</published>
    <arxiv:primary_category term="stat.ME"/>
    <author>
      <name>Bryant Chen</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
    <author>
      <name>Elias Bareinboim</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1503.01603v1</id>
    <title>External Validity: From Do-Calculus to Transportability Across Populations</title>
    <updated>2015-03-05T10:58:30Z</updated>
    <link href="https://arxiv.org/abs/1503.01603v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1503.01603v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The generalizability of empirical findings to new environments, settings or populations, often called "external validity," is essential in most scientific explorations. This paper treats a particular problem of generalizability, called "transportability," defined as a license to transfer causal effects learned in experimental studies to a new population, in which only observational studies can be conducted. We introduce a formal representation called "selection diagrams" for expressing knowledge about differences and commonalities between populations of interest and, using this representation, we reduce questions of transportability to symbolic derivations in the do-calculus. This reduction yields graph-based procedures for deciding, prior to observing any data, whether causal effects in the target population can be inferred from experimental findings in the study population. When the answer is affirmative, the procedures identify what experimental and observational findings need be obtained from the two populations, and how they can be combined to ensure bias-free transport.</summary>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2015-03-05T10:58:30Z</published>
    <arxiv:comment>Published in at http://dx.doi.org/10.1214/14-STS486 the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org). arXiv admin note: text overlap with arXiv:1312.7485</arxiv:comment>
    <arxiv:primary_category term="stat.ME"/>
    <arxiv:journal_ref>Statistical Science 2014, Vol. 29, No. 4, 579-595</arxiv:journal_ref>
    <author>
      <name>Judea Pearl</name>
    </author>
    <author>
      <name>Elias Bareinboim</name>
    </author>
    <arxiv:doi>10.1214/14-STS486</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1214/14-STS486" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1411.7014v1</id>
    <title>Efficient Algorithms for Bayesian Network Parameter Learning from Incomplete Data</title>
    <updated>2014-11-25T20:39:51Z</updated>
    <link href="https://arxiv.org/abs/1411.7014v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1411.7014v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose an efficient family of algorithms to learn the parameters of a Bayesian network from incomplete data. In contrast to textbook approaches such as EM and the gradient method, our approach is non-iterative, yields closed form parameter estimates, and eliminates the need for inference in a Bayesian network. Our approach provides consistent parameter estimates for missing data problems that are MCAR, MAR, and in some cases, MNAR. Empirically, our approach is orders of magnitude faster than EM (as our approach requires no inference). Given sufficient data, we learn parameters that can be orders of magnitude more accurate.</summary>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2014-11-25T20:39:51Z</published>
    <arxiv:primary_category term="cs.LG"/>
    <author>
      <name>Guy Van den Broeck</name>
    </author>
    <author>
      <name>Karthika Mohan</name>
    </author>
    <author>
      <name>Arthur Choi</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1408.1479v1</id>
    <title>Logarithmic-Time Updates and Queries in Probabilistic Networks</title>
    <updated>2014-08-07T06:22:13Z</updated>
    <link href="https://arxiv.org/abs/1408.1479v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1408.1479v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In this paper we propose a dynamic data structure that supports efficient algorithms for updating and querying singly connected Bayesian networks (causal trees and polytrees).  In the conventional algorithms, new evidence in absorbed in time O(1) and queries are processed in time O(N), where N is the size of the network.  We propose a practical algorithm which, after a preprocessing phase, allows us to answer queries in time O(log N) at the expense of O(logn N) time per evidence absorption.  The usefulness of sub-linear processing time manifests itself in applications requiring (near) real-time response over large probabilistic databases.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2014-08-07T06:22:13Z</published>
    <arxiv:comment>Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Arthur L. Delcher</name>
    </author>
    <author>
      <name>Adam J. Grove</name>
    </author>
    <author>
      <name>Simon Kasif</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1312.7485v1</id>
    <title>A General Algorithm for Deciding Transportability of Experimental Results</title>
    <updated>2013-12-29T00:54:47Z</updated>
    <link href="https://arxiv.org/abs/1312.7485v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1312.7485v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Generalizing empirical findings to new environments, settings, or populations is essential in most scientific explorations. This article treats a particular problem of generalizability, called "transportability", defined as a license to transfer information learned in experimental studies to a different population, on which only observational studies can be conducted. Given a set of assumptions concerning commonalities and differences between the two populations, Pearl and Bareinboim (2011) derived sufficient conditions that permit such transfer to take place. This article summarizes their findings and supplements them with an effective procedure for deciding when and how transportability is feasible. It establishes a necessary and sufficient condition for deciding when causal effects in the target population are estimable from both the statistical information available and the causal information transferred from the experiments. The article further provides a complete algorithm for computing the transport formula, that is, a way of combining observational and experimental information to synthesize bias-free estimate of the desired causal relation. Finally, the article examines the differences between transportability and other variants of generalizability.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-12-29T00:54:47Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <arxiv:journal_ref>Journal of Causal Inference, 2013; 1(1): 107-134</arxiv:journal_ref>
    <author>
      <name>Elias Bareinboim</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
    <arxiv:doi>10.1515/jci-2012-0004</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1515/jci-2012-0004" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3422v1</id>
    <title>A Constraint Propagation Approach to Probabilistic Reasoning</title>
    <updated>2013-03-27T19:55:56Z</updated>
    <link href="https://arxiv.org/abs/1304.3422v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.3422v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The paper demonstrates that strict adherence to probability theory does not preclude the use of concurrent, self-activated constraint-propagation mechanisms for managing uncertainty. Maintaining local records of sources-of-belief allows both predictive and diagnostic inferences to be activated simultaneously and propagate harmoniously towards a stable equilibrium.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:55:56Z</published>
    <arxiv:comment>Appears in Proceedings of the First Conference on Uncertainty in Artificial Intelligence (UAI1985)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3103v1</id>
    <title>Learning Link-Probabilities in Causal Trees</title>
    <updated>2013-03-27T19:53:34Z</updated>
    <link href="https://arxiv.org/abs/1304.3103v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.3103v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>A learning algorithm is presented which given the structure of a causal tree, will estimate its link probabilities by sequential measurements on the leaves only. Internal nodes of the tree represent conceptual (hidden) variables inaccessible to observation. The method described is incremental, local, efficient, and remains robust to measurement imprecisions.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:53:34Z</published>
    <arxiv:comment>Appears in Proceedings of the Second Conference on Uncertainty in Artificial Intelligence (UAI1986)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Igor Roizer</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.3102v1</id>
    <title>Distributed Revision of Belief Commitment in Multi-Hypothesis Interpretations</title>
    <updated>2013-03-27T19:53:29Z</updated>
    <link href="https://arxiv.org/abs/1304.3102v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.3102v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper extends the applications of belief-networks to include the revision of belief commitments, i.e., the categorical acceptance of a subset of hypotheses which, together, constitute the most satisfactory explanation of the evidence at hand. A coherent model of non-monotonic reasoning is established and distributed algorithms for belief revision are presented. We show that, in singly connected networks, the most satisfactory explanation can be found in linear time by a message-passing algorithm similar to the one used in belief updating. In multiply-connected networks, the problem may be exponentially hard but, if the network is sparse, topological considerations can be used to render the interpretation task tractable. In general, finding the most probable combination of hypotheses is no more complex than computing the degree of belief for any individual hypothesis. Applications to medical diagnosis are illustrated.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:53:29Z</published>
    <arxiv:comment>Appears in Proceedings of the Second Conference on Uncertainty in Artificial Intelligence (UAI1986)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2736v1</id>
    <title>The Recovery of Causal Poly-Trees from Statistical Data</title>
    <updated>2013-03-27T19:48:18Z</updated>
    <link href="https://arxiv.org/abs/1304.2736v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.2736v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Poly-trees are singly connected causal networks in which variables may arise from multiple causes. This paper develops a method of recovering ply-trees from empirically measured probability distributions of pairs of variables. The method guarantees that, if the measured distributions are generated by a causal process structured as a ply-tree then the topological structure of such tree can be recovered precisely and, in addition, the causal directionality of the branches can be determined up to the maximum extent possible. The method also pinpoints the minimum (if any) external semantics required to determine the causal relationships among the variables considered.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:48:18Z</published>
    <arxiv:comment>Appears in Proceedings of the Third Conference on Uncertainty in Artificial Intelligence (UAI1987)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>George Rebane</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2730v1</id>
    <title>Structuring Causal Tree Models with Continuous Variables</title>
    <updated>2013-03-27T19:47:50Z</updated>
    <link href="https://arxiv.org/abs/1304.2730v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.2730v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper considers the problem of invoking auxiliary, unobservable variables to facilitate the structuring of causal tree models for a given set of continuous variables. Paralleling the treatment of bi-valued variables in [Pearl 1986], we show that if a collection of coupled variables are governed by a joint normal distribution and a tree-structured representation exists, then both the topology and all internal relationships of the tree can be uncovered by observing pairwise dependencies among the observed variables (i.e., the leaves of the tree). Furthermore, the conditions for normally distributed variables are less restrictive than those governing bi-valued variables. The result extends the applications of causal tree models which were found useful in evidential reasoning tasks.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:47:50Z</published>
    <arxiv:comment>Appears in Proceedings of the Third Conference on Uncertainty in Artificial Intelligence (UAI1987)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Lei Xu</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2716v1</id>
    <title>Do We Need Higher-Order Probabilities and, If So, What Do They Mean?</title>
    <updated>2013-03-27T19:46:42Z</updated>
    <link href="https://arxiv.org/abs/1304.2716v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.2716v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The apparent failure of individual probabilistic expressions to distinguish uncertainty about truths from uncertainty about probabilistic assessments have prompted researchers to seek formalisms where the two types of uncertainties are given notational distinction. This paper demonstrates that the desired distinction is already a built-in feature of classical probabilistic models, thus, specialized notations are unnecessary.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:46:42Z</published>
    <arxiv:comment>Appears in Proceedings of the Third Conference on Uncertainty in Artificial Intelligence (UAI1987)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2379v1</id>
    <title>Causal Networks: Semantics and Expressiveness</title>
    <updated>2013-03-27T19:45:27Z</updated>
    <link href="https://arxiv.org/abs/1304.2379v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.2379v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Dependency knowledge of the form "x is independent of y once z is known" invariably obeys the four graphoid axioms, examples include probabilistic and database dependencies.  Often, such knowledge can be represented efficiently with graphical structures such as undirected graphs and directed acyclic graphs (DAGs).  In this paper we show that the graphical criterion called d-separation is a sound rule for reading independencies from any DAG based on a causal input list drawn from a graphoid.  The rule may be extended to cover DAGs that represent functional dependencies as well as conditional dependencies.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:45:27Z</published>
    <arxiv:comment>Appears in Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence (UAI1988)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Tom S. Verma</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.2355v1</id>
    <title>On the Logic of Causal Models</title>
    <updated>2013-03-27T19:43:07Z</updated>
    <link href="https://arxiv.org/abs/1304.2355v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.2355v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper explores the role of Directed Acyclic Graphs (DAGs) as a representation of conditional independence relationships.  We show that DAGs offer polynomially sound and complete inference mechanisms for inferring conditional independence relationships from a given causal set of such relationships.  As a consequence, d-separation, a graphical criterion for identifying independencies in a DAG, is shown to uncover more valid independencies then any other criterion.  In addition, we employ the Armstrong property of conditional independence to show that the dependence relationships displayed by a DAG are inherently consistent, i.e. for every DAG D there exists some probability distribution P that embodies all the conditional independencies displayed in D and none other.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:43:07Z</published>
    <arxiv:comment>Appears in Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence (UAI1988)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Dan Geiger</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1507v1</id>
    <title>Deciding Consistency of Databases Containing Defeasible and Strict Information</title>
    <updated>2013-03-27T19:38:23Z</updated>
    <link href="https://arxiv.org/abs/1304.1507v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.1507v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose a norm of consistency for a mixed set of defeasible and strict sentences, based on a probabilistic semantics.  This norm establishes a clear distinction between knowledge bases depicting exceptions and those containing outright contradictions.  We then define a notion of entailment based also on probabilistic considerations and provide a characterization of the relation between consistency and entailment. We derive necessary and sufficient conditions for consistency, and provide a simple decision procedure for testing consistency and deciding whether a sentence is entailed by a database.  Finally, it is shown that if al1 sentences are Horn clauses, consistency and entailment can be tested in polynomial time. </summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:38:23Z</published>
    <arxiv:comment>Appears in Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI1989)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Moises Goldszmidt</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1505v1</id>
    <title>d-Separation: From Theorems to Algorithms</title>
    <updated>2013-03-27T19:38:11Z</updated>
    <link href="https://arxiv.org/abs/1304.1505v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.1505v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>An efficient algorithm is developed that identifies all independencies implied by the topology of a Bayesian network.  Its correctness and maximality stems from the soundness and completeness of d-separation with respect to probability theory.  The algorithm runs in time O (l E l) where E is the number of edges in the network.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T19:38:11Z</published>
    <arxiv:comment>Appears in Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence (UAI1989)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Dan Geiger</name>
    </author>
    <author>
      <name>Tom S. Verma</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1304.1108v1</id>
    <title>On the Equivalence of Causal Models</title>
    <updated>2013-03-27T13:57:02Z</updated>
    <link href="https://arxiv.org/abs/1304.1108v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1304.1108v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Scientists often use directed acyclic graphs (days) to model the qualitative structure of causal theories, allowing the parameters to be estimated from observational data.  Two causal models are equivalent if there is no experiment which could distinguish one from the other.  A canonical representation for causal models is presented which yields an efficient graphical criterion for deciding equivalence, and provides a theoretical basis for extracting causal structures from empirical data.  This representation is then extended to the more general case of an embedded causal model, that is, a dag in which only a subset of the variables are observable.  The canonical representation presented here yields an efficient algorithm for determining when two embedded causal models reflect the same dependency information.  This algorithm leads to a model theoretic definition of causation in terms of statistical dependencies.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-27T13:57:02Z</published>
    <arxiv:comment>Appears in Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence (UAI1990)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Tom S. Verma</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.5435v1</id>
    <title>An Algorithm for Deciding if a Set of Observed Independencies Has a Causal Explanation</title>
    <updated>2013-03-13T12:55:46Z</updated>
    <link href="https://arxiv.org/abs/1303.5435v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1303.5435v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In a previous paper [Pearl and Verma, 1991] we presented an algorithm for extracting causal influences from independence information, where a causal influence was defined as the existence of a directed arc in all minimal causal models consistent with the data.  In this paper we address the question of deciding whether there exists a causal model that explains ALL the observed dependencies and independencies.  Formally, given a list M of conditional independence statements, it is required to decide whether there exists a directed acyclic graph (dag) D that is perfectly consistent with M, namely, every statement in M, and no other, is reflected via dseparation in D.  We present and analyze an effective algorithm that tests for the existence of such a day, and produces one, if it exists.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-13T12:55:46Z</published>
    <arxiv:comment>Appears in Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence (UAI1992)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Tom S. Verma</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.5406v1</id>
    <title>Reasoning With Qualitative Probabilities Can Be Tractable</title>
    <updated>2013-03-13T12:52:54Z</updated>
    <link href="https://arxiv.org/abs/1303.5406v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1303.5406v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We recently described a formalism for reasoning with if-then rules that re expressed with different levels of firmness [18].  The formalism interprets these rules as extreme conditional probability statements, specifying orders of magnitude of disbelief, which impose constraints over possible rankings of worlds.  It was shown that, once we compute a priority function Z+ on the rules, the degree to which a given query is confirmed or denied can be computed in O(log n`) propositional satisfiability tests, where n is the number of rules in the knowledge base.  In this paper, we show that computing Z+ requires O(n2 X log n) satisfiability tests, not an exponential number as was conjectured in [18], which reduces to polynomial complexity in the case of Horn expressions.  We also show how reasoning with imprecise observations can be incorporated in our formalism and how the popular notions of belief revision and epistemic entrenchment are embodied naturally and tractably.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-13T12:52:54Z</published>
    <arxiv:comment>Appears in Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence (UAI1992)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Moises Goldszmidt</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1501v1</id>
    <title>Deciding Morality of Graphs is NP-complete</title>
    <updated>2013-03-06T14:22:53Z</updated>
    <link href="https://arxiv.org/abs/1303.1501v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1303.1501v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>In order to find a causal explanation for data presented in the form of covariance and concentration matrices it is necessary to decide if the graph formed by such associations is a projection of a directed acyclic graph (dag).  We show that the general problem of deciding whether such a dag exists is NP-complete.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-06T14:22:53Z</published>
    <arxiv:comment>Appears in Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI1993)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Tom S. Verma</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1303.1455v1</id>
    <title>From Conditional Oughts to Qualitative Decision Theory</title>
    <updated>2013-03-06T14:18:29Z</updated>
    <link href="https://arxiv.org/abs/1303.1455v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1303.1455v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The primary theme of this investigation is a decision theoretic account of conditional ought statements (e.g., "You ought to do A, if C") that rectifies glaring deficiencies in classical deontic logic.  The resulting account forms a sound basis for qualitative decision theory, thus providing a framework for qualitative planning under uncertainty.  In particular, we show that adding causal relationships (in the form of a single graph) as part of an epistemic state is sufficient to facilitate the analysis of action sequences, their consequences, their interaction with observations, their expected utilities and, hence, the synthesis of plans and strategies under uncertainty.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-03-06T14:18:29Z</published>
    <arxiv:comment>Appears in Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI1993)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.6835v1</id>
    <title>A Probabilistic Calculus of Actions</title>
    <updated>2013-02-27T14:18:47Z</updated>
    <link href="https://arxiv.org/abs/1302.6835v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.6835v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We present a symbolic machinery that admits both probabilistic and causal information about a given domain and produces probabilistic statements about the effect of actions and the impact of observations.  The calculus admits two types of conditioning operators: ordinary Bayes conditioning, P(y|X = x), which represents the observation X = x, and causal conditioning, P(y|do(X = x)), read the probability of Y = y conditioned on holding X constant (at x) by deliberate action. Given a mixture of such observational and causal sentences, together with the topology of the causal graph, the calculus derives new conditional probabilities of both types, thus enabling one to quantify the effects of actions (and policies) from partially specified knowledge bases, such as Bayesian networks in which some conditional probabilities may not be available.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-27T14:18:47Z</published>
    <arxiv:comment>Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.6809v1</id>
    <title>On Testing Whether an Embedded Bayesian Network Represents a Probability Model</title>
    <updated>2013-02-27T14:16:13Z</updated>
    <link href="https://arxiv.org/abs/1302.6809v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.6809v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Testing the validity of probabilistic models containing unmeasured (hidden) variables is shown to be a hard task.  We show that the task of testing whether models are structurally incompatible with the data at hand, requires an exponential number of independence evaluations, each of the form: "X is conditionally independent of Y, given Z."  In contrast, a linear number of such evaluations is required to test a standard Bayesian network (one per vertex).  On the positive side, we show that if a network with hidden variables G has a tree skeleton, checking whether G represents a given probability model P requires the polynomial number of such independence evaluations.  Moreover, we provide an algorithm that efficiently constructs a tree-structured Bayesian network (with hidden variables) that represents P if such a network exists, and further recognizes when such a network does not exist.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-27T14:16:13Z</published>
    <arxiv:comment>Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Dan Geiger</name>
    </author>
    <author>
      <name>Azaria Paz</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.6784v1</id>
    <title>Counterfactual Probabilities: Computational Methods, Bounds and Applications</title>
    <updated>2013-02-27T14:13:50Z</updated>
    <link href="https://arxiv.org/abs/1302.6784v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.6784v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability.  In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true.  When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely.  However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed.  This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-27T14:13:50Z</published>
    <arxiv:comment>Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Alexander Balke</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4977v1</id>
    <title>Probabilistic Evaluation of Sequential Plans from Causal Models with Hidden Variables</title>
    <updated>2013-02-20T15:23:09Z</updated>
    <link href="https://arxiv.org/abs/1302.4977v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.4977v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The paper concerns the probabilistic evaluation of plans in the presence of unmeasured variables, each plan consisting of several concurrent or sequential actions.  We establish a graphical criterion for recognizing when the effects of a given plan can be predicted from passive observations on measured variables only.  When the criterion is satisfied, a closed-form expression is provided for the probability that the plan will achieve a specified goal.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-20T15:23:09Z</published>
    <arxiv:comment>Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
    <author>
      <name>James M. Robins</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4976v1</id>
    <title>On the Testability of Causal Models with Latent and Instrumental Variables</title>
    <updated>2013-02-20T15:23:04Z</updated>
    <link href="https://arxiv.org/abs/1302.4976v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.4976v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Certain causal models involving unmeasured variables induce no independence constraints among the observed variables but imply, nevertheless, inequality contraints on the observed distribution.  This paper derives a general formula for such instrumental variables, that is, exogenous variables that directly affect some variables but not all.  With the help of this formula, it is possible to test whether a model involving instrumental variables may account for the data, or, conversely, whether a given variables can be deemed instrumental.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-20T15:23:04Z</published>
    <arxiv:comment>Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4948v1</id>
    <title>Testing Identifiability of Causal Effects</title>
    <updated>2013-02-20T15:20:35Z</updated>
    <link href="https://arxiv.org/abs/1302.4948v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.4948v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper concerns the probabilistic evaluation of the effects of actions in the presence of unmeasured variables.  We show that the identification of causal effect between a singleton variable X and a set of variables Y can be accomplished systematically, in time polynomial in the number of variables in the graph.  When the causal effect is identifiable, a closed-form expression can be obtained for the probability that the action will achieve a specified goal, or a set of goals.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-20T15:20:35Z</published>
    <arxiv:comment>Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>David Galles</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.4929v1</id>
    <title>Counterfactuals and Policy Analysis in Structural Models</title>
    <updated>2013-02-20T15:18:56Z</updated>
    <link href="https://arxiv.org/abs/1302.4929v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.4929v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, determination of liability, and policy analysis.  We present a method of revaluating counterfactuals when the underlying causal model is represented by structural models - a nonlinear generalization of the simultaneous equations models commonly used in econometrics and social sciences.  This new method provides a coherent means for evaluating policies involving the control of variables which, prior to enacting the policy were influenced by other variables in the system.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-20T15:18:56Z</published>
    <arxiv:comment>Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Alexander Balke</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1302.3595v1</id>
    <title>Identifying Independencies in Causal Graphs with Feedback</title>
    <updated>2013-02-13T14:15:49Z</updated>
    <link href="https://arxiv.org/abs/1302.3595v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1302.3595v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We show that the d -separation criterion constitutes a valid test for conditional independence relationships that are induced by feedback systems involving discrete variables.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-02-13T14:15:49Z</published>
    <arxiv:comment>Appears in Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence (UAI1996)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
    <author>
      <name>Rina Dechter</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.3898v1</id>
    <title>Probabilities of Causation: Bounds and Identification</title>
    <updated>2013-01-16T15:53:00Z</updated>
    <link href="https://arxiv.org/abs/1301.3898v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.3898v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper deals with the problem of estimating the probability that one event was a cause of another in a given scenario. Using structural-semantical definitions of the probabilities of necessary or sufficient causation (or both), we show how to optimally bound these quantities from data obtained in experimental and observational studies, making minimal assumptions concerning the data-generating process. In particular, we strengthen the results  of Pearl (1999) by weakening the data-generation assumptions and deriving theoretically sharp bounds on the probabilities of causation. These results delineate precisely how empirical data can be used both in settling questions of attribution and in solving attribution-related problems of decision making. </summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-01-16T15:53:00Z</published>
    <arxiv:comment>Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Jin Tian</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2312v1</id>
    <title>Causal Discovery from Changes</title>
    <updated>2013-01-10T16:26:39Z</updated>
    <link href="https://arxiv.org/abs/1301.2312v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.2312v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose a new method of discovering causal structures, based on the detection of local, spontaneous changes in the underlying data-generating model. We analyze the classes of structures that are equivalent relative to a stream of distributions produced by local changes, and devise algorithms that output graphical representations of these equivalence classes. We present experimental results, using simulated data, and examine the errors associated with detection of changes and recovery of structures. </summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-01-10T16:26:39Z</published>
    <arxiv:comment>Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Jin Tian</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2300v1</id>
    <title>Direct and Indirect Effects</title>
    <updated>2013-01-10T16:25:47Z</updated>
    <link href="https://arxiv.org/abs/1301.2300v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.2300v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The direct effect of one eventon another can be defined and measured byholding constant all intermediate variables between the two.Indirect effects present conceptual andpractical difficulties (in nonlinear models), because they cannot be isolated by holding certain variablesconstant. This paper shows a way of defining any path-specific effectthat does not invoke blocking the remainingpaths.This permits the assessment of a more naturaltype of direct and indirect effects, one thatis applicable in both linear and nonlinear models. The paper establishesconditions under which such assessments can be estimated consistentlyfrom experimental and nonexperimental data,and thus extends path-analytic techniques tononlinear and nonparametric models.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-01-10T16:25:47Z</published>
    <arxiv:comment>Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.2275v1</id>
    <title>Causes and Explanations: A Structural-Model Approach --- Part 1: Causes</title>
    <updated>2013-01-10T16:23:57Z</updated>
    <link href="https://arxiv.org/abs/1301.2275v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.2275v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We propose a new definition of actual causes, using structural equations to model counterfactuals.We show that the definitions yield a plausible and elegant account ofcausation that handles well examples which have caused problems forother definitions and resolves major difficulties in the traditionalaccount.  In a companion paper, we show how the definition of causality can beused to give an elegant definition of (causal) explanation.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2013-01-10T16:23:57Z</published>
    <arxiv:comment>Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001), later extended version is arXiv:cs/0011012</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Joseph Y. Halpern</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0608v1</id>
    <title>On the Testable Implications of Causal Models with Hidden Variables</title>
    <updated>2012-12-12T15:58:54Z</updated>
    <link href="https://arxiv.org/abs/1301.0608v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.0608v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The validity OF a causal model can be tested ONLY IF      the model imposes constraints ON     the probability distribution that governs the generated data. IN the      presence OF unmeasured variables,     causal models may impose two types OF constraints : conditional      independencies,     AS READ through the d - separation criterion, AND     functional constraints, FOR     which no general criterion IS available.This paper offers a systematic      way OF identifying functional constraints AND, thus,     facilitates the task OF testing causal models AS well AS inferring      such models FROM data. </summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2012-12-12T15:58:54Z</published>
    <arxiv:comment>Appears in Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI2002)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Jin Tian</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0560v1</id>
    <title>Generalized Instrumental Variables</title>
    <updated>2012-12-12T15:55:41Z</updated>
    <link href="https://arxiv.org/abs/1301.0560v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.0560v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper concerns the assessment of direct causal effects from a combination of: (i) non-experimental data, and (ii) qualitative domain knowledge. Domain knowledge is encoded in the form of a directed acyclic graph (DAG), in which all interactions are assumed linear, and some variables are presumed to be unobserved. We provide a generalization of the well-known method of Instrumental Variables, which allows its application to models with few conditional independeces. </summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2012-12-12T15:55:41Z</published>
    <arxiv:comment>Appears in Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI2002)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Carlos Brito</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1301.0557v1</id>
    <title>Qualitative MDPs and POMDPs: An Order-Of-Magnitude Approximation</title>
    <updated>2012-12-12T15:55:30Z</updated>
    <link href="https://arxiv.org/abs/1301.0557v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1301.0557v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>We develop a qualitative theory of Markov Decision Processes (MDPs) and Partially Observable MDPs that can be used to model sequential decision making tasks when only qualitative information is available. Our approach is based upon an order-of-magnitude approximation of both probabilities and utilities, similar to epsilon-semantics. The result is a qualitative theory that has close ties with the standard maximum-expected-utility theory and is amenable to general planning techniques.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2012-12-12T15:55:30Z</published>
    <arxiv:comment>Appears in Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI2002)</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Blai Bonet</name>
    </author>
    <author>
      <name>Judea Pearl</name>
    </author>
  </entry>
</feed>
